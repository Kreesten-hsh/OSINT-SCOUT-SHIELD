import sys
# Force flush
sys.stdout.reconfigure(line_buffering=True)

import asyncio
import json
import os

# Ajout du dossier parent au path pour les imports si n√©cessaire
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

print("[Worker] STARTING...", flush=True)

try:
    print("[Worker] Importing Redis...", flush=True)
    import redis.asyncio as redis
    print("[Worker] Importing Scraper Engine...", flush=True)
    from runners.engine import OsintScout
    print("[Worker] Importing Fraud Analyzer...", flush=True)
    from analysis.processor import FraudAnalyzer
    print("[Worker] Imports OK.", flush=True)
except Exception as e:
    print(f"[Worker] ‚ùå Import Error: {e}", flush=True)
    sys.exit(1)

# Configuration
REDIS_URL = os.getenv("REDIS_URL", "redis://redis:6379/0")
QUEUE_TASKS = "osint_to_scan"
QUEUE_RESULTS = "osint_results"

async def process_task(scout, analyzer, task_data):
    target_url = task_data.get("url")
    print(f"\n[Worker] üõ†Ô∏è  Nouvelle t√¢che re√ßue : {target_url}", flush=True)
    
    # 1. √âTAPE COLLECTE (Scraper)
    print(f"[Worker] üï∑Ô∏è  Lancement collecte Playwright...", flush=True)
    try:
        evidence = await scout.scrape_target(target_url)
    except Exception as e:
        print(f"[Worker] ‚ùå Erreur critique scraper : {e}", flush=True)
        return None

    if evidence.get("status") == "ERROR":
        print(f"[Worker] ‚ö†Ô∏è  √âchec collecte : {evidence.get('error')}", flush=True)
        return {
            "task_id": task_data.get("id"),
            "status": "FAILED",
            "error": evidence.get("error")
        }

    # 2. √âTAPE ANALYSE (AUTOMATIS√âE)
    print(f"[Worker] üß†  Analyse Automatis√©e (R√®gles) en cours...", flush=True)
    content_text = evidence.get("content_text", "")
    analysis_result = analyzer.analyze_text(content_text)
    
    score = analysis_result["risk_score"]
    is_alert = analysis_result["is_alert"]
    
    print(f"[Worker] üìä  R√©sultat Analyse : Score {score}/100 | Alerte: {is_alert}", flush=True)
    if is_alert:
        print(f"[Worker] üö®  MENACE D√âTECT√âE ! Cat√©gories : {[cat['name'] for cat in analysis_result['categories']]}", flush=True)

    # 3. AGGR√âGATION & RAPPORT
    final_report = {
        "task_id": task_data.get("id"),
        "url": target_url,
        "timestamp": evidence["timestamp_utc"],
        "evidence_hash": evidence["proof_sha256"],
        "risk_score": score,
        "is_alert": is_alert,
        "details": {
            "evidence_metadata": evidence["metadata"],
            "analysis": analysis_result
        }
    }
    
    return final_report

async def run_worker():
    print("[Worker] üöÄ D√©marrage du Worker d'Orchestration OSINT...", flush=True)
    
    # Init Connexions
    try:
        r = redis.from_url(REDIS_URL, decode_responses=True)
        await r.ping()
        print(f"[Worker] ‚úÖ Connect√© √† Redis ({REDIS_URL})", flush=True)
    except Exception as e:
        print(f"[Worker] ‚ùå Impossible de se connecter √† Redis : {e}", flush=True)
        return

    # Init Moteurs
    print("[Worker] üîß Initialisation Scraper & NLP...", flush=True)
    scout = OsintScout(headless=True)
    # Le chemin est relatif √† la racine /app dans Docker
    try:
        analyzer = FraudAnalyzer(rules_path="config/rules.json")
    except Exception as e:
        print(f"[Worker] ‚ùå Erreur Init Analyzer : {e}", flush=True)
        return
    
    print(f"[Worker] üëÇ En attente de t√¢ches sur la file '{QUEUE_TASKS}'...", flush=True)
    
    try:
        while True:
            # R√©cup√©ration bloquante (timeout 1s pour permettre le CTRL+C)
            item = await r.blpop(QUEUE_TASKS, timeout=1)
            
            if not item:
                continue
                
            # blpop retourne (nom_queue, valeur)
            _, data_raw = item
            
            try:
                task_data = json.loads(data_raw)
                report = await process_task(scout, analyzer, task_data)
                
                if report:
                    # Envoi du r√©sultat dans la file correspondante
                    # Dans un syst√®me r√©el, l'API consommerait cette file
                    await r.rpush(QUEUE_RESULTS, json.dumps(report))
                    print(f"[Worker] üì§ Rapport envoy√© vers '{QUEUE_RESULTS}'", flush=True)
                    
            except json.JSONDecodeError:
                print(f"[Worker] ‚ùå Erreur d√©codage JSON : {data_raw}", flush=True)
            except Exception as e:
                print(f"[Worker] ‚ùå Erreur Inattendue : {e}", flush=True)

    except asyncio.CancelledError:
        print("[Worker] Arr√™t demand√©...", flush=True)
    finally:
        print("[Worker] Nettoyage ressources...", flush=True)
        await scout.stop()
        await r.aclose()
        print("[Worker] üëã Arr√™t complet.", flush=True)

if __name__ == "__main__":
    try:
        asyncio.run(run_worker())
    except KeyboardInterrupt:
        pass
